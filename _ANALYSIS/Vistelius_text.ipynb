{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vistelius text digitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package used to work with OCR of text\n",
    "from tika import parser\n",
    "\n",
    "# Linear algebra package\n",
    "import numpy as np\n",
    "\n",
    "# Tabular data package\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype, is_string_dtype\n",
    "\n",
    "# Operating system package\n",
    "import os\n",
    "\n",
    "# Parallellization modules and packages\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# Regular expressions package\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pdf\n",
    "pdf_text = \"../_DATA/Vistelius_scans_text_OCR.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 09:07:23,440 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.19/tika-server-1.19.jar to C:\\Users\\u0108248\\AppData\\Local\\Temp\\tika-server.jar.\n",
      "2019-10-17 09:07:40,205 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.19/tika-server-1.19.jar.md5 to C:\\Users\\u0108248\\AppData\\Local\\Temp\\tika-server.jar.md5.\n",
      "2019-10-17 09:07:40,862 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
      "2019-10-17 09:07:45,873 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    }
   ],
   "source": [
    "# Parse pdf file\n",
    "pdf_parsed = parser.from_file(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from parsed pdf file\n",
    "text_parsed = pdf_parsed['content'].strip().replace(\"\\n\\n\", \"\\n\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty lines from text\n",
    "text_parsed_noempty = []\n",
    "\n",
    "for index, line in enumerate(text_parsed):\n",
    "    if len(line) != 0:\n",
    "        text_parsed_noempty.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Save text without empty lines as text file\n",
    "with open(\"../text_parsed_noempty.txt\", 'w') as f:\n",
    "    for line in text_parsed_noempty:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split double lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 (47°20' ,106°55'). Bt granite porphyraceous. Tr3-J1. Abdaryn m~ssif (V.I.Ushakov,1964). 0 0 + . (47 09'20\",134 4A'l5\"J .. , Granite -porphyry. K2. Det.:H2o -0.26 (A .G.Kandaurov,1974) . \n",
      "3486 2831 - (61°10 1 ,144°06'). Granite. K2. Vega massif. P.V.Artemenko. Det.:H2o+-0.52 (l.M.Speranskaya?l960). o' o 2832- {52 59' ,113 14'). Granosyenite. Tr {F.N.Lyudofun,1967). \n"
     ]
    }
   ],
   "source": [
    "# Specific correction for lines containing two sampleID-coordinates pairs\n",
    "double_lines_indices = []\n",
    "regex_double = re.compile(r\"[0\\-\\s]*[\\(\\{]+[0-9iIl!p&\\s]{2,}°?[0-9]\")\n",
    "\n",
    "for index, line in enumerate(text_parsed_noempty):\n",
    "    if len(regex_double.findall(line)) >= 2:\n",
    "        print(index, line)\n",
    "        double_lines_indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000, 3486]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_lines_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_2000 = text_parsed_noempty[2000][:95]\n",
    "part2_2000 = text_parsed_noempty[2000][95:]\n",
    "part1_3486 = text_parsed_noempty[3486][:112]\n",
    "part2_3486 = text_parsed_noempty[3486][112:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del text_parsed_noempty[2000]\n",
    "del text_parsed_noempty[3485]\n",
    "text_parsed_noempty.insert(2000, part2_2000)\n",
    "text_parsed_noempty.insert(2000, part1_2000)\n",
    "text_parsed_noempty.insert(3487, part2_3486)\n",
    "text_parsed_noempty.insert(3487, part1_3486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(51°29\\'30\",110°10\\'). Granite fine-grained. Tr. M.I.Kodachigova (V.A.Novikov,1966) . ',\n",
       " \"(47°20' ,106°55'). Bt granite porphyraceous. Tr3-J1. Abdaryn m~ssif (V.I.Ushakov,1964). 0 0 + .\",\n",
       " ' (47 09\\'20\",134 4A\\'l5\"J .. , Granite -porphyry. K2. Det.:H2o -0.26 (A .G.Kandaurov,1974) . ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_parsed_noempty[1999:2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2829 - (46°22\\'58\",136°18\\'10\"). Granite. K2. Det.:H2o -0.85 (V.K.Matushkin?l974). ',\n",
       " '2830- (47°22\\'25\",139°00\\'30\"). Bt -Amf granodiorite. K2-Pg1. Oth.:S03-0.19 (V.A.Yarmolyuk?l956). ',\n",
       " \"2831 - (61°10 1 ,144°06'). Granite. K2. Vega massif. P.V.Artemenko. Det.:H2o+-0.52 (l.M.Speranskaya?l960). o' o \",\n",
       " \"2832- {52 59' ,113 14'). Granosyenite. Tr {F.N.Lyudofun,1967). \",\n",
       " \"2833 - {52°16'20 11 ,117°36'30 11 ). Granite porphyraceous. J3. Sretensky massif. M.E.Kazakova. Oth.:Ba0-0.08? so3-0.20? \"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_parsed_noempty[3485:3490]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_lines(lines):\n",
    "    regex =  re.compile(r\"^[\\-\\.·\\s,:;\\'0]*[0-9~iIl&TJ\\)]+[L\\s\\.·]*[\\-~]{1,2}\")\n",
    "    regex2 = re.compile(r\"^[\\-\\.·\\s,;:\\'0]*[0-9~iIl&TJ\\)]+[L\\s\\.·]*[\\-~]{1,2}\\s?$\")\n",
    "    regex3 = re.compile(r\"^[0\\-\\s]*[\\(\\{]+[0-9iIl!p&\\s]{2,}°?[0-9]\")\n",
    "\n",
    "    actual_lines = []\n",
    "    empty_entries_index = []\n",
    "    missing_entries = []\n",
    "    # Check for systematic error\n",
    "    hit0 = []\n",
    "    i = 0\n",
    "    empty_entry_section = False\n",
    "\n",
    "    for index, test in enumerate(lines):\n",
    "        \n",
    "        # Check if entry starts with sampleID and nothing else\n",
    "        if len(regex2.findall(test)) > 0:\n",
    "            missing_entries.append(lines[index])\n",
    "#             print('hit0', test, index, len(missing_entries))\n",
    "            hit0.append(test)\n",
    "            # Exception for sampleID 3061 that where an empty section immediatley follows another empty section:\n",
    "            # Needs a rule instead of this exception.\n",
    "            if test.startswith(\"'3061\"):\n",
    "                i -= 1\n",
    "            if empty_entry_section:\n",
    "                i += 1\n",
    "            \n",
    "        # Check if entry starts with sampleID and has more information behind it\n",
    "        if len(regex.findall(test)) > 0:\n",
    "            actual_lines.append(test)\n",
    "            index_to_add = index\n",
    "            empty_entry_section = False\n",
    "            # If line in actual_lines only contains sampleID, keep its index for later use\n",
    "            if len(regex2.findall(actual_lines[-1])) > 0:\n",
    "                empty_entries_index.append(len(actual_lines) - 1)\n",
    "        else:\n",
    "            actual_lines[-1] = actual_lines[-1] + lines[index]\n",
    "            \n",
    "        # Check if entry starts with coordinates\n",
    "        if len(regex3.findall(test)) > 0:\n",
    "            empty_entry_section = True\n",
    "            missing_entries[i] = missing_entries[i] + lines[index]\n",
    "#             print(missing_entries[i])\n",
    "            # Check for systematic error\n",
    "            assert(missing_entries[i][:4] == hit0[i][:4])\n",
    "            j = i\n",
    "#             print(i, j)\n",
    "            \n",
    "        if empty_entry_section:\n",
    "            # Check again if entry starts with coordinates\n",
    "            if len(regex3.findall(test)) > 0:\n",
    "                i += 1\n",
    "            else:\n",
    "                missing_entries[j] = missing_entries[j] + lines[index]\n",
    "#                 print('hit1', test)\n",
    "    \n",
    "    # Replace the former saved 'empty' lines with actual corresponding info\n",
    "    for index, line in zip(empty_entries_index, missing_entries):\n",
    "        actual_lines[index] = line\n",
    "\n",
    "    return actual_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "text_parsed_corr = correct_lines(text_parsed_noempty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace common errors for minutes and seconds symbols\n",
    "text_parsed_corr_repl = []\n",
    "\n",
    "for item in text_parsed_corr:\n",
    "    item = item.replace(\" 1 \", \"'\")\n",
    "    item = item.replace(\" 11 \", \"\\\"\")\n",
    "    item = item.replace(\"''\", \"\\\"\")\n",
    "    \n",
    "    text_parsed_corr_repl.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4660"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_parsed_corr_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Save corrected lines as text file\n",
    "with open(\"../text_parsed_corr_repl.txt\", 'w') as f:\n",
    "    for line in text_parsed_corr_repl:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines in saved file that are containing double entries\n",
    "missed_entries = [2990, 3656, 3876, 4070]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 460- (52°10'10\",110°22'30\"). Granite porphyraceous. Tr-J1 (V.I.Pelepyagin,1975). - --- - ------==-='--=------------ .,,,j, - ' -\n",
      "479 480- (50°17' ,108°28'). Granite leucocratic. J 1. Otytey massif. N.P.Mel'nikova (V.V.Starchenko,1968). ----=---~-------=---=--- - ---- -- --- I• -\n",
      "480 ~-·----------\n",
      "500 500- (60°50',152°48'). Granite subalkaline . K2. Upper -Yam massif. Oth .:co2-0.10 (A .A.Dontsov , 1946). ----- • ~---=---==-- --- -\n",
      "501 ~ -~- .. ---·~--\n",
      "521 520- {45°33'50\",135°25'). Granite. K2. Yamutinzin massif (N.K.Flyaga , 1964) . --- -=---=-====-==-:: .. ·~ \"\"-\n",
      "532 531- (47°15',135°12'}. Bt granite medium-grained. K2• E.L.Trusov (N.F.Smirnov,1961}. -\n",
      "562 ~---- -\n",
      "563 ., - ~ -~--\n"
     ]
    }
   ],
   "source": [
    "# Check which lines do not contain actual information\n",
    "regex4 = re.compile(r\"\\-$\")\n",
    "\n",
    "for index, line in enumerate(text_parsed_corr_repl):\n",
    "    if len(regex4.findall(line)) != 0:\n",
    "        print(index, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regular expression setup:**\n",
    "- Group 01 - Sample ID\n",
    "- Group 02 - Lattitude degrees\n",
    "- Group 03 - Lattitude minutes\n",
    "- Group 04 - Lattitude seconds\n",
    "- Group 05 - Longitude degrees\n",
    "- Group 06 - Longitude minutes\n",
    "- Group 07 - Longitudes seconds\n",
    "- Group 08 - Longitude direction (W)\n",
    "- Group 09 - Rock name\n",
    "- Group 10 - Whole-rock age\n",
    "- Group 11 - Massif name (optional)\n",
    "- Group 12 - Analyst name (optional)\n",
    "- Group 13 - Interpretation of \"oth.\" and \"det.\" (optional)\n",
    "- Group 14 - Author and year of the original report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test regex for sampleID and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression for finding sampleID and coordinates\n",
    "regex_sampleID_coordinates = re.compile(r\"^[\\-\\.·,:\\s0\\']*\" + \n",
    "                                        r\"([0-9GSO~iIlJT\\)&\\']+)\" + # SampleID\n",
    "                                        r\"[\\-\\s\\(\\.\\{L\\'~0·]*\" + \n",
    "                                        r\"([0-9iIl!pS~o\\-•Z\\.,&]{2,})\" +  # Lattitude degrees\n",
    "                                        r\"[°\\s90Qg]*\" + \n",
    "                                        r\"([0-9iIl!pS~roJ\\()\\.]{2,})\" +  # Lattitude minutes\n",
    "                                        r\"['\\\\ji\\s1;]*\" + \n",
    "                                        r\"([0-9iIl!pS~norJf]{2,})?\" +  # Lattitude seconds\n",
    "                                        r\"[\\\"\\'\\s,~\\.;\\)]*\" +\n",
    "                                        r\"([0-9iIl!pS~of\\s\\$sa·t£]{1,})\" +  # Longitude degrees\n",
    "                                        r\"[°\\s90Qg]*\" +\n",
    "                                        r\"([0-9iIl!pS~\\soJ\\-Zj]{2,})\" +  # Longitude minutes\n",
    "                                        r\"['\\\\\\s]*\" +\n",
    "                                        r\"([0-9iIl!pS~o]{2,})?\" +  # Longitude seconds\n",
    "                                        r\"[\\\"\\)\\}\\.wW]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'^[\\-\\.·,:\\s0\\\\']*([0-9GSO~iIlJT\\)&\\\\']+)[\\-\\s\\(\\.\\{L\\\\'~0·]*([0-9iIl!pS~o\\-•Z\\.,&]{2,})[°\\s90Qg]*([0-9iIl!pS~roJ\\()\\.]{2,})[\\'\\\\ji\\s1;]*([0-9iIl!pS~norJf]{2,})?[\\\"\\\\'\\s,~\\.;\\)]*([0-9iIl!pS~of\\s\\$sa·t£]{1,})[°\\s90Qg]*([0-9iIl!pS~\\soJ\\-Zj]{2,})[\\'\\\\\\s]*([0-9iIl!pS~o]{2,})?[\\\"\\)\\}\\.wW]*',\n",
       "re.UNICODE)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_sampleID_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~-·----------\n",
      "~---- -\n",
      "., - ~ -~--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4657"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all samples are picked up by sampleID and coordinates regex\n",
    "counter = 0\n",
    "\n",
    "for line in text_parsed_corr_repl:\n",
    "    if len(regex_sampleID_coordinates.findall(line)) == 0:\n",
    "        print(line)\n",
    "    else:\n",
    "        counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sampleID and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parsed_corr_repl_checked = open(\"../_TEMP/Text/text_parsed_corr_repl_checked.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parsed_corr_repl_checked_list = []\n",
    "\n",
    "for line in text_parsed_corr_repl_checked:\n",
    "    text_parsed_corr_repl_checked_list.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parsed_corr_repl_checked.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41- (54°20\\' ,117°57\\'40\"). Granite leucocratic alkaline . J3 (N.V.Kuzheleva,1959) . \\n',\n",
       " \"42- (61°17' ,149°23'). Bt granite (alaskite). K1. East -Butugychag massif (P.N .Sp i ridonov,1940). \\n\",\n",
       " \"43- (67°50' ,178°50'W). Granite. K1. Iul'tin massif. Oth.:B2o3-0.0l, co2-0.08 (A . I .Kyshtymov i l959). \\n\",\n",
       " \"44- (52°28' ,140°19'). Granite. K2-Pg. A.N .Geraskina. Det.:co2-0.14 (V.P.Polikanov , 1974). \\n\",\n",
       " \"45- (50°12',112°39'). Granite leucocratic . J1_2. 0th . : so3-tr. (I.I.Kozyrevil968). \\n\",\n",
       " \"46- (50°56' ,113°18'). Granite leucocratic. J2_3. V.Petrikovetz (A.I.Shevtsov,1967). \\n\",\n",
       " '47- (47°27\\'48~,138°23\\'24\") . Granite. Pg1. Vayga massif (F.G.Fedchin,1975) . \\n',\n",
       " \"48- (60°27' ,l4p0 53'). Bt granite. K2. Vega massif (Yu.I.Korshikov,1966). \\n\",\n",
       " '49- (52°06\\'50\",115°58\\') Granite leucocratic alkaline porphyraceous. J3. Zangan massif . D.M.Shuster (V.A.Ulanov,1961). \\n',\n",
       " \"50- (61°19' ,149°15'). Bt granite leucocratic fine -grained. K1. West-B~tugychag massif. K.A.Baklanova (M .S.Venchugova,1939). \\n\",\n",
       " \"51- (51°05' ,113°33'). Granite fine -grained. J3. Kalangin massif. D.M.Shust er (E.V.Barabashev,1961) . \\n\",\n",
       " \"52- (49°49' ,139°09'). Granite. K2-Pg. R.A.Sokolova (P.A.Epov,1952). \\n\",\n",
       " \"53- (67°57' ,177°19'). Granosyenite. K1. Kutum massif. S.M.Shadskaya (K.V . laraketsov,1955). \\n\",\n",
       " \"54- (62°45' ,158°49'). Aplite. K2. Chula massif. I .S.Ryabova . Det.:H2o+-0 . 19 (I . P.Vasetsky,1965). \\n\",\n",
       " '55- (53°35\\'30\",118°31\\'50\"). Granite alkaline. J3. N.A.Lebedeva (S.P.Smelovsky,1968). \\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_parsed_corr_repl_checked_list[40:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK Add exceptions for parentheses in Massif name\n",
    "# Specify more precisely in regex how to handle \"Det.\" and \"Oth.\" keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parsed_corr_repl_checked_list_regex_sub = []\n",
    "\n",
    "for line in text_parsed_corr_repl_checked_list:\n",
    "    # Always select first item since 'subn' returns a tuple\n",
    "    line = re.subn(r\"·\", \"\", line)[0]\n",
    "    line = re.subn(r\"•\", \"\", line)[0]\n",
    "    line = re.subn(r\"([^A-z0-9])(\\s+)([A-z0-9])\", r\"|\\1\\3\", line)[0]\n",
    "    line = re.subn(r\"([A-z0-9])(\\s+)([^A-z0-9])\", r\"\\1|\\3\", line)[0]\n",
    "    line = re.subn(r\"\\|\\(([A-z\\s\\-~,]+)\\|\\)(massif)\", r\" \\1 \\2\", line)[0]\n",
    "    text_parsed_corr_repl_checked_list_regex_sub.append(line.replace(\"\\x00\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1578- (44°29\\'40\",136°08\\'30\") |.Granite|(granophyre) |.Pg1_2|.Mutukhin Oprichn in massif|.N.M.Nikitina|(S|.A.Korenbaum,1973). \\n',\n",
       " \"1579- (50°02' ,112°35')|.Granite|-porphyry|.J3|.Kharalgin massif||.A|.I.Fedorova|(N.K.Dmitrochenko,1968). \\n\",\n",
       " \"1580- (49°33' ,112°37')|.Two mica granite||.J2|.Khalzan mass if||.L.S.Voronova|(N|.K.Dmit rochenko|,1964) . \\n\"]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_parsed_corr_repl_checked_list_regex_sub[1577:1580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Save text without empty lines as text file\n",
    "with open(\"../_TEMP/Text/text_parsed_regex_sub.txt\", 'w') as f:\n",
    "    for line in text_parsed_corr_repl_checked_list_regex_sub:\n",
    "        f.write(f\"{line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleID_coordinates = []\n",
    "\n",
    "for line in text_parsed_corr_repl_checked_list:\n",
    "    # Leave out [0] first to get all matches, \n",
    "    # instead of only the first, for checking in next cell\n",
    "    sampleID_coordinates.append(regex_sampleID_coordinates.findall(line)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that every match only contains one pair of sampleID and coordinates\n",
    "for list_ in sampleID_coordinates:\n",
    "    if len(list_) > 1:\n",
    "        print(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleID_coordinates = pd.DataFrame(sampleID_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_misspells(a):\n",
    "    a = a.str.replace(\"l\", \"1\")\n",
    "    a = a.str.replace(\"I\", \"1\")\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleID_coordinates = df_sampleID_coordinates.apply(replace_misspells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_entries = []\n",
    "counter = 0\n",
    "\n",
    "for index, row in df_sampleID_coordinates.iterrows():   \n",
    "    for item in row:\n",
    "        try:\n",
    "            _ = int(item)\n",
    "        except:\n",
    "            if item != \"\":\n",
    "                if index not in wrong_entries:\n",
    "                    wrong_entries.append(index)\n",
    "                    counter += 1\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong_entries = df_sampleID_coordinates.iloc[wrong_entries,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wrong entries to disk; to be cleaned manually\n",
    "df_wrong_entries.to_excel(\"../_NEEDS_CLEANING/Vistelius_text_to_be_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 'W' longitudes into consideration --> Change longitude to negative value to represent this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code snippets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "\n",
    "def convert_pdf_into_pages(pdf, output_loc):\n",
    "    inputpdf = PdfFileReader(open(pdf, \"rb\"))\n",
    "    filename = pdf.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    for i in range(inputpdf.numPages):\n",
    "        output = PdfFileWriter()\n",
    "        output.addPage(inputpdf.getPage(i))\n",
    "        \n",
    "        if i < 10:\n",
    "            page_format = f\"00{i}\"\n",
    "        elif i < 100:\n",
    "            page_format = f\"0{i}\"\n",
    "        else:\n",
    "            page_format = f\"{i}\"\n",
    "            \n",
    "        with open(f\"{output_loc}/{filename}_page_{page_format}.pdf\", \"wb\") as outputStream:\n",
    "            output.write(outputStream)\n",
    "            \n",
    "# Reference: https://stackoverflow.com/questions/490195/split-a-multi-page-pdf-file-into-multiple-pdf-files-with-python"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "convert_pdf_into_pages(pdf_text, \"../_DATA/text_pages/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "^[\\-\\.·,:\\s0\\']*\n",
    "([0-9GSO~iIlJT\\)&\\'\\|]+)  # Group 1 - SampleID\n",
    "[\\-\\s\\(\\.\\{L\\\\'\\'~0·\\|]*\n",
    "([0-9iIl!pS~o\\-•Z\\.,&\\|]{2,})  # Group 2 - Lattitude degrees\n",
    "[°\\s90Qg\\|]*\n",
    "([0-9iIl!pS~roJ\\()\\.\\|]{2,})  # Group 3 - Lattitude minutes\n",
    "[\\'\\\\ji\\s1;\\|]*\n",
    "([0-9iIl!pS~norJf\\|]{2,})?  # Group 4 - Lattitude seconds\n",
    "[\\\"\\\\'\\s,~\\.;\\)\\|]*\n",
    "([0-9iIl!pS~of\\s\\$sa·t£\\|]{1,})  # Group 5 - Longitude degrees\n",
    "[°\\s90Qg\\|]*\n",
    "([0-9iIl!pS~\\soJ\\-Zj\\|]{2,})  # Group 6 - Longitude minutes\n",
    "[\\'\\\\\\s\\|]*\n",
    "([0-9iIl!pS~oq]{2,})?  # Group 7 - Longitude seconds\n",
    "([Ww]?)?  # Group 8 - Longitude direction (W)\n",
    "[\\\"\\)\\}\\.,wWt\\s\\'j\\|:]*\n",
    "([A-z\\s\\-~\\(\\)·0\\.\\|\\?\\']{3,})  # Group 9 - Rock name\n",
    "[\\.\\|,]{2,}\n",
    "([A-z0-9\\s\\-~\\']+)  # Group 10 - Whole rock age\n",
    "[\\.\\|\\s,]*\n",
    "([A-z0-9\\s\\-\\|\\'\\?]{2,})?  # Group 11 - Massif name (optional)\n",
    "(?(11)[\\.\\|\\s,]+|[\\.\\|\\s,]*)\n",
    "([A-z0-9\\s\\.,\\'!\\|]{4,})?  # Group 12 - Analyst name (optional)\n",
    "(?(12)[\\.\\|\\s,]+|[\\.\\|\\s,]*)\n",
    "([A-z0-9\\s:\\.,~\\-+\\|\\?]+)?  # Group 13 - Interpretation of \"oth.\" and \"det.\" (optional)\n",
    "(?(13)[\\.\\|\\s,]+|[\\.\\|\\s,]*)\n",
    "[\\.\\|\\s,\\(\\{]+\n",
    "([A-z\\.,0-9\\s\\|\\'~\\-!\\?]+)  # Group 14 - Author and year of the original report\n",
    "[\\)\\}\\.\\s]+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pdf_table_extractor]",
   "language": "python",
   "name": "conda-env-pdf_table_extractor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
